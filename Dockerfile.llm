FROM ubuntu:22.04

# Install dependencies including CURL development libraries
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    curl \
    libcurl4-openssl-dev \
    && rm -rf /var/lib/apt/lists/*

# Build llama.cpp
WORKDIR /app
RUN git clone https://github.com/ggerganov/llama.cpp && \
    cd llama.cpp && \
    mkdir build && cd build && \
    cmake .. -DLLAMA_SERVER=ON -DLLAMA_CURL=ON && \
    make -j$(nproc)

# Create models directory
RUN mkdir -p /models

# Copy your model from root models directory
COPY models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf /models/

EXPOSE 8080

CMD ["/app/llama.cpp/build/bin/server", "-m", "/models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf", "--host", "0.0.0.0", "--port", "8080", "--ctx-size", "2048", "--threads", "4"]